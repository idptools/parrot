#!/usr/bin/env python

import argparse
import os

import torch
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger, WandbLogger

from parrot.brnn_architecture import BRNN_MtM, BRNN_MtO, ParrotDataModule
from parrot.tools import validate_args


def main():
    # Parse the command line arguments
    parser = argparse.ArgumentParser(
        description="Train and test a bi-directional RNN using entire sequence."
    )

    parser.add_argument(
        "data_file", help="path to tsv file with format: <idx> <sequence> <data>"
    )
    parser.add_argument("output_network", help="location to save the trained network")
    parser.add_argument(
        "-d",
        "--datatype",
        metavar="dtype",
        type=str,
        required=True,
        help="REQUIRED. Format of the input data file, must be 'sequence' or 'residues'",
    )
    parser.add_argument(
        "-c",
        "--classes",
        type=int,
        metavar="num_classes",
        required=True,
        help="REQUIRED. Number of output classes, for regression put 1",
    )
    parser.add_argument(
        "-hs",
        "--hidden-size",
        default=10,
        type=int,
        metavar="hidden_size",
        help="hidden vector size (def=10)",
    )
    parser.add_argument(
        "-nl",
        "--num-layers",
        default=1,
        type=int,
        metavar="num_layers",
        help="number of layers per direction (def=1)",
    )
    parser.add_argument(
        "-lr",
        "--learning-rate",
        default=0.001,
        type=float,
        metavar="learning_rate",
        help="(def=0.001)",
    )
    parser.add_argument(
        "-b",
        "--batch",
        default=32,
        type=int,
        metavar="batch_size",
        help="size of training batch (def=32)",
    )
    parser.add_argument(
        "-e",
        "--epochs",
        default=100,
        type=int,
        metavar="num_epochs",
        help="number of training epochs (def=100)",
    )
    parser.add_argument(
        "--split",
        default="",
        metavar="split_file",
        type=str,
        help="file indicating how to split datafile into training, validation, and test sets",
    )
    parser.add_argument(
        "--set-fractions",
        nargs=3,
        default=[0.7, 0.15, 0.15],
        type=float,
        dest="setFractions",
        metavar=("train", "val", "test"),
        help="proportion of dataset that should be divided into training, validation, and test sets",
    )
    parser.add_argument(
        "--encode",
        default="onehot",
        type=str,
        metavar="encoding_scheme",
        help="'onehot' (default), 'biophysics', or specify a path to a user-created scheme",
    )
    parser.add_argument(
        "--exclude-seq-id",
        dest="excludeSeqID",
        action="store_true",
        help="use if data_file lacks sequence IDs in the first column of each line",
    )
    parser.add_argument(
        "--force-cpu",
        dest="forceCPU",
        action="store_true",
        help="force network to train on CPU, even if GPU is available",
    )
    parser.add_argument(
        "--gpu-id",
        dest="gpu_id",
        type=int,
        help="User defined control over which CUDA device will be used by parrot",
    )
    parser.add_argument(
        "--ignore-warnings",
        "-w",
        dest="ignore_warnings",
        action="store_true",
        help="Do not display warnings for dataset structure",
    )
    parser.add_argument(
        "--save-splits",
        dest="save_splits",
        action="store_true",
        help="Save a split-file using the random splits from this run",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Flag which, if provided, causes output to terminal to be more descriptive",
    )
    parser.add_argument(
        "--silent",
        action="store_true",
        help="Flag which, if provided, ensures no output is generated to the terminal",
    )

    args = parser.parse_args()

    # Validate arguments and initialize network
    data_file = validate_args.check_file_exists(args.data_file, "Datafile")
    network_file = os.path.abspath(args.output_network)
    filename_prefix, output_dir = validate_args.split_file_and_directory(network_file)

    if args.split != "":
        split_file = validate_args.check_file_exists(args.split, "Split-file")
    else:
        split_file = None

    if args.save_splits:
        save_splits_output = filename_prefix + "_split_file.txt"
    else:
        save_splits_output = None

    encoding_scheme, encoder, input_size = validate_args.set_encoding_scheme(
        args.encode
    )

    # Set up the ParrotDataModule
    datamodule = ParrotDataModule(
        data_file,
        num_classes=args.classes,
        datatype=args.datatype,
        batch_size=args.batch,
        encode=args.encode,
        fractions=args.setFractions,
        split_file=split_file,
        excludeSeqID=args.excludeSeqID,
        ignore_warnings=args.ignore_warnings,
        save_splits=args.save_splits,
    )

    # Prepare the data
    datamodule.prepare_data()
    datamodule.setup()

    # Initialize the appropriate BRNN model
    if args.datatype == "sequence":
        model = BRNN_MtO(
            input_size=datamodule.input_size,
            lstm_hidden_size=args.hidden_size,
            num_lstm_layers=args.num_layers,
            num_classes=args.classes,
            problem_type=datamodule.problem_type,
            datatype=args.datatype,
            batch_size=args.batch,
            learn_rate=args.learning_rate,
        )
    elif args.datatype == "residues":
        model = BRNN_MtM(
            input_size=datamodule.input_size,
            lstm_hidden_size=args.hidden_size,
            num_lstm_layers=args.num_layers,
            num_classes=args.classes,
            problem_type=datamodule.problem_type,
            datatype=args.datatype,
            learn_rate=args.learning_rate,
        )

    # Set up callbacks
    early_stop_callback = EarlyStopping(
        monitor="epoch_val_loss", min_delta=0.00, patience=3, verbose=True, mode="min"
    )

    checkpoint_callback = ModelCheckpoint(
        monitor="epoch_val_loss",
        dirpath="checkpoints/",
        filename="epoch{epoch:02d}-val_loss{epoch_val_loss:.2f}",
        save_top_k=1,
        mode="min",
    )

    # Set up logger
    if "WANDB_API_KEY" in os.environ:
        logger = WandbLogger(project="parrot_project", name="parrot_run")
        logger.watch(model)
    else:
        logger = CSVLogger("logs", name="parrot_model")

    # Set up trainer
    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator="gpu" if torch.cuda.is_available() and not args.forceCPU else "cpu",
        devices=1 if args.gpu_id is None else [args.gpu_id],
        callbacks=[early_stop_callback, checkpoint_callback],
        logger=logger,
        log_every_n_steps=10,
        enable_progress_bar=not args.silent,
        enable_model_summary=not args.silent,
    )

    # Output to std out
    if not args.silent:
        print("\nPARROT with user-specified parameters")
        print("-------------------------------------")
        if args.verbose:
            print(f"Train on: {trainer.accelerator}")
            print(f"Datatype: {args.datatype}")
            print(f"ML Task: {datamodule.problem_type}")
            print(f"Learning rate: {args.learning_rate}")
            print(f"Number of layers: {args.num_layers}")
            print(f"Hidden vector size: {args.hidden_size}")
            print(f"Batch size: {args.batch}\n")
        print("Validation set loss per epoch:")

    # Train the model
    trainer.fit(model, datamodule=datamodule)

    # Test the model
    trainer.test(model, datamodule=datamodule)

    # Save the model
    trainer.save_checkpoint(args.output_network)

    if not args.silent:
        print(f'\nTest Loss: {trainer.callback_metrics["test_loss"]:.4f}')

    # If using wandb, finish the run
    if isinstance(logger, WandbLogger):
        import wandb

        wandb.finish()


if __name__ == "__main__":
    main()
